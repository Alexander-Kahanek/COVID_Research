{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bit31a300f32e4a4979894c2ccf59316df7",
   "display_name": "Python 3.8.3 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loaded...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px # choropleth maps\n",
    "from IPython.display import Image\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "# plotly maps\n",
    "# import plotly.figure_factory as ff\n",
    "# from urllib.request import urlopen\n",
    "\n",
    "# sys.path.append(os.path.abspath(\"C:/Users/Alex/Documents/My Data Files/COVID Research/analysis/mention_2_hashtag.py\"))\n",
    "\n",
    "# from analysis.functions.mention_2_hashtag import * \n",
    "# from analysis.functions.datamanip import *\n",
    "\n",
    "# n grams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "raw = pd.read_csv('flair.joined.tweets.csv')\n",
    "\n",
    "# changing date to more readable format\n",
    "raw['created_at'] = pd.to_datetime(raw['created_at'])\n",
    "\n",
    "# getting seperated date and time columns\n",
    "raw['date'] = raw['created_at'].dt.date\n",
    "raw['week'] = raw['created_at'].dt.week\n",
    "raw['time'] = raw['created_at'].dt.time\n",
    "raw['hour'] = raw['created_at'].dt.hour\n",
    "\n",
    "min_wk = raw['week'].min()\n",
    "max_wk = raw['week'].max()\n",
    "\n",
    "min_date = raw['date'].min()\n",
    "max_date = raw['date'].max()\n",
    "\n",
    "# changing na to None\n",
    "raw = raw.fillna('None')\n",
    "\n",
    "raw = raw[raw['sentiment'] != 'None']\n",
    "\n",
    "raw['is_negative'] = [1 if 'NEGATIVE' in str(sent) else 0 for sent in raw['sentiment']]\n",
    "raw['is_positive'] = [1 if 'POSITIVE' in str(sent) else 0 for sent in raw['sentiment']]\n",
    "\n",
    "\n",
    "def convert_fips(unknown_fips_list, fin):\n",
    "    \n",
    "    def convert(fipsline):\n",
    "        name, postal, fips= fipsline.strip().split('\\t')\n",
    "\n",
    "        return {fips: name}\n",
    "\n",
    "    fips_dict = {f: n \n",
    "                for dic in [convert(line)for line in open(fin, 'r')]\n",
    "                for f, n in dic.items()}\n",
    "\n",
    "    return [fips_dict[f'{unknown:02d}'] for unknown in unknown_fips_list]\n",
    "\n",
    "raw = raw[raw['statefips'] != 'None']\n",
    "\n",
    "raw['state_name'] = convert_fips([int(float(fips)) for fips in raw['statefips']],\n",
    "                     '../analysis/functions/state.fips.txt')\n",
    "\n",
    "us_state_abbrev = json.load(open('state_abbreviations.json'))\n",
    "\n",
    "raw['state_abv'] = [us_state_abbrev[s] for s in raw['state_name']]\n",
    "\n",
    "raw['fips'] = [f'{int(float(state)):02d}{int(float(county)):03d}' for i, state, county in raw[['statefips', 'countyfips']].itertuples()]\n",
    "raw['count'] = 1\n",
    "# raw.head()\n",
    "\n",
    "all_splits = pd.to_datetime(['2020-03-05', '2020-03-26', '2020-05-01'])\n",
    "raw['stage'] = ['s:1' if date < all_splits[0] else 's:2' if date < all_splits[1] else 's:3' if date < all_splits[2] else 's:4' for date in raw['date']]\n",
    "\n",
    "\n",
    "\n",
    "#########################\n",
    "# thresholds\n",
    "thresholds = [0.8, 0.9, 0.95]\n",
    "for thresh in thresholds:\n",
    "    raw[f't:{thresh}'] = [1 if float(conf) > thresh else 0 for conf in raw['sent_confidence']]\n",
    "\n",
    "col = 't:0.8'\n",
    "raw['category'] = ['NEUT' if t == 0 else 'POS' if p == 1 else 'NEG' for i, n, p, t in raw[['is_negative', 'is_positive', col]].itertuples()]\n",
    "raw['is_neutral'] = [1 if cat == 'NEUT' else 0 for cat in raw['category']]\n",
    "raw['is_positive'] = [1 if cat == 'POS' else 0 for cat in raw['category']]\n",
    "raw['is_negative'] = [1 if cat == 'NEG' else 0 for cat in raw['category']]\n",
    "\n",
    "raw['is_neutral2'] = raw['is_neutral']\n",
    "raw['is_positive2'] = raw['is_positive']\n",
    "raw['is_negative2'] = raw['is_negative']\n",
    "\n",
    "raw['is_neutral3'] = raw['is_neutral']\n",
    "raw['is_positive3'] = raw['is_positive']\n",
    "raw['is_negative3'] = raw['is_negative']\n",
    "\n",
    "##################\n",
    "# cdc\n",
    "\n",
    "keywords = ['social distancing', 'social distance', 'physical distance', '6 feet', 'stay at home', 'school isolation', 'isolation', 'stay home', 'avoid touching', 'mask', 'covering', 'face shield', 'wear a mask', 'surgical mask', 'N95 respirator', 'wearing gloves', 'face shields', 'facial covering', 'skin protection', 'eye protection', 'ppe', 'wash hands', 'hand sanitizer', 'disinfect', 'clean', 'detergent', 'handwashing', 'hand hygiene', 'prevention hygiene', 'sprays', 'concentrates', 'wipes', 'routine cleaning', 'bleach solution', 'test', 'business closure']\n",
    "\n",
    "topics = []\n",
    "indexes = {i:0 for i in range(len(raw.index))}\n",
    "\n",
    "for i, topic in enumerate(keywords):\n",
    "    topics.append([1 if topic in text else 0 for text in raw['ogtext']])\n",
    "\n",
    "for i, kw in enumerate(topics):\n",
    "    for data_ind, value in enumerate(topics[i]):\n",
    "        indexes[data_ind] += value\n",
    "\n",
    "raw['in_cdc'] = [indexes[i] if 0 <= indexes[i] <= 1 else 1 for i in indexes]\n",
    "\n",
    "cdc = raw[raw['in_cdc'] == 1]\n",
    "\n",
    "cdc_splits = pd.to_datetime(['2020-03-12', '2020-04-20', '2020-05-14'])\n",
    "cdc['stage'] = ['s:1' if date < cdc_splits[0] else 's:2' if date < cdc_splits[1] else 's:3' if date < cdc_splits[2] else 's:4' for date in cdc['date']]\n",
    "\n",
    "# print(f'there are a total of {len(cdc.index)} tweets after subsetting for cdc keywords')\n",
    "# print(raw)\n",
    "# print(cdc)\n",
    "print('loaded...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['id_str', 'created_at', 'follower_count', 'friends_count', 'statefips',\n",
       "       'countyfips', 'countyname', 'is_urban', 'ogtext', 'cleantext',\n",
       "       'mentions', 'hashtags', 'pos', 'ner', 'sentiment', 'sent_confidence',\n",
       "       'date', 'week', 'time', 'hour', 'is_negative', 'is_positive',\n",
       "       'state_name', 'state_abv', 'fips', 'count', 'stage', 't:0.8', 't:0.9',\n",
       "       't:0.95', 'category', 'is_neutral', 'is_neutral2', 'is_positive2',\n",
       "       'is_negative2', 'is_neutral3', 'is_positive3', 'is_negative3',\n",
       "       'in_cdc'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "there are a total of 53272 tweets after subsetting for cdc keywords\n"
     ]
    }
   ],
   "source": [
    "keywords = ['social distancing', 'social distance', 'physical distance', '6 feet', 'stay at home', 'school isolation', 'isolation', 'stay home', 'avoid touching', 'mask', 'covering', 'face shield', 'wear a mask', 'surgical mask', 'N95 respirator', 'wearing gloves', 'face shields', 'facial covering', 'skin protection', 'eye protection', 'ppe', 'wash hands', 'hand sanitizer', 'disinfect', 'clean', 'detergent', 'handwashing', 'hand hygiene', 'prevention hygiene', 'sprays', 'concentrates', 'wipes', 'routine cleaning', 'bleach solution', 'test', 'business closure']\n",
    "\n",
    "topics = []\n",
    "indexes = {i:0 for i in range(len(raw.index))}\n",
    "\n",
    "for i, topic in enumerate(keywords):\n",
    "    topics.append([1 if topic in text else 0 for text in raw['ogtext']])\n",
    "\n",
    "for i, kw in enumerate(topics):\n",
    "    for data_ind, value in enumerate(topics[i]):\n",
    "        indexes[data_ind] += value\n",
    "\n",
    "raw['in_cdc'] = [indexes[i] if 0 <= indexes[i] <= 1 else 1 for i in indexes]\n",
    "\n",
    "cdc = raw[raw['in_cdc'] == 1]\n",
    "\n",
    "print(f'there are a total of {len(cdc.index)} tweets after subsetting for cdc keywords')"
   ]
  },
  {
   "source": [
    "# getting counties by rural/urban"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw.groupby(['fips']).agg({'count':'count', 'is_urban':'sum', 'is_negative':'mean', 'is_positive':'mean', 'is_neutral':'mean'}).reset_index()\n",
    "df['is_rural'] = df['count'] - df['is_urban']\n",
    "df['p_urban'] = df['is_urban'] / df['count']\n",
    "\n",
    "df = df[df['count'] > 15]\n",
    "\n",
    "# sns.regplot(y='is_negative', x='p_urban', data=df, marker='+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.corr()**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "# x= df['p_urban']\n",
    "# y= df['is_negative']\n",
    "\n",
    "# print(scipy.stats.pearsonr(x, y))"
   ]
  },
  {
   "source": [
    "# t test between urban and rural counties"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df.index))\n",
    "\n",
    "# df2 = df[df['p_urban'] < 0.8]\n",
    "# df2 = df2[df2['p_urban'] > 0.2]\n",
    "# df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "negative:\n",
      "len urban= 830, len rural= 182\n",
      "meanUrban= 0.5768273405328975, stdUrban= 0.08968712292612052\n",
      "meanRural= 0.5833472394796978, stdRural= 0.1063719154051495\n",
      "         t                p\n",
      "-0.7691173158706105 0.44257817384399456\n",
      "\n",
      "positive:\n",
      "len urban= 830, len rural= 182\n",
      "meanUrban= 0.29213852840404303, stdUrban= 0.08271359810864314\n",
      "meanRural= 0.29182402353422937, stdRural= 0.09948418419024763\n",
      "         t                p\n",
      "0.039743138239857694 0.9683311113931015\n",
      "\n",
      "neutral:\n",
      "len urban= 830, len rural= 182\n",
      "meanUrban= 0.13103413106305942, stdUrban= 0.05051981034437689\n",
      "meanRural= 0.12482873698607284, stdRural= 0.058787628429605734\n",
      "         t                p\n",
      "1.3210763469296816 0.18771866425205697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "cats = 'negative positive neutral'.split(' ')\n",
    "\n",
    "for cat in cats:\n",
    "    print(f'{cat}:')\n",
    "\n",
    "    urban = raw[raw['is_urban']==1].groupby(['fips']).agg({'count':'count', f'is_{cat}':'mean'}).reset_index()\n",
    "    rural = raw[raw['is_urban']==0].groupby(['fips']).agg({'count':'count', f'is_{cat}':'mean'}).reset_index()\n",
    "\n",
    "    urban = urban[urban['count'] > 15]\n",
    "    rural = rural[rural['count'] > 15]\n",
    "\n",
    "    print(f'len urban= {len(urban.index)}, len rural= {len(rural.index)}')\n",
    "    print(f'meanUrban= {urban[f\"is_{cat}\"].mean()}, stdUrban= {urban[f\"is_{cat}\"].std()}')\n",
    "    print(f'meanRural= {rural[f\"is_{cat}\"].mean()}, stdRural= {rural[f\"is_{cat}\"].std()}')\n",
    "\n",
    "    from scipy.stats import ttest_ind\n",
    "    t, p = ttest_ind(urban[f'is_{cat}'], rural[f'is_{cat}'], equal_var=False)\n",
    "    print('         t                p')\n",
    "    print(t, p)\n",
    "    print()\n",
    "\n",
    "# sns.distplot(urban['is_negative'], hist = True, kde = True,\n",
    "#                  kde_kws = {'linewidth': 3}, label=\"urban\")\n",
    "\n",
    "# sns.distplot(rural['is_negative'], hist = True, kde = True,\n",
    "#                  kde_kws = {'linewidth': 3}, label=\"rural\", axlabel=\"proportion of negative sentiment\")\n",
    "\n",
    "# plt.title(\"COVID-19 Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "negative:\nlen urban= 355, len rural= 52\nmeanUrban= 0.6112191650318727, stdUrban= 0.08908389553737095\nmeanRural= 0.6543482085240492, stdRural= 0.07851853162870684\n         t                p\n-3.6332091678131966 0.0005226805793239376\n\npositive:\nlen urban= 355, len rural= 52\nmeanUrban= 0.24547082218192756, stdUrban= 0.08224891919147614\nmeanRural= 0.21730468428056784, stdRural= 0.07157451983033206\n         t                p\n2.5976012601735405 0.011369514256739112\n\nneutral:\nlen urban= 355, len rural= 52\nmeanUrban= 0.1433100127861997, stdUrban= 0.05654815836476976\nmeanRural= 0.12834710719538311, stdRural= 0.04113606841943789\n         t                p\n2.321311160150001 0.02274569131763659\n\n"
     ]
    }
   ],
   "source": [
    "cats = 'negative positive neutral'.split(' ')\n",
    "\n",
    "for cat in cats:\n",
    "    print(f'{cat}:')\n",
    "\n",
    "    urban = cdc[cdc['is_urban']==1].groupby(['fips']).agg({'count':'count', f'is_{cat}':'mean'}).reset_index()\n",
    "    rural = cdc[cdc['is_urban']==0].groupby(['fips']).agg({'count':'count', f'is_{cat}':'mean'}).reset_index()\n",
    "\n",
    "    urban = urban[urban['count'] > 15]\n",
    "    rural = rural[rural['count'] > 15]\n",
    "\n",
    "    print(f'len urban= {len(urban.index)}, len rural= {len(rural.index)}')\n",
    "    print(f'meanUrban= {urban[f\"is_{cat}\"].mean()}, stdUrban= {urban[f\"is_{cat}\"].std()}')\n",
    "    print(f'meanRural= {rural[f\"is_{cat}\"].mean()}, stdRural= {rural[f\"is_{cat}\"].std()}')\n",
    "\n",
    "    from scipy.stats import ttest_ind\n",
    "    t, p = ttest_ind(urban[f'is_{cat}'], rural[f'is_{cat}'], equal_var=False)\n",
    "    print('         t                p')\n",
    "    print(t, p)\n",
    "    print()"
   ]
  }
 ]
}