{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bit31a300f32e4a4979894c2ccf59316df7",
   "display_name": "Python 3.8.3 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# running socioeconomic results with cdc subset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loaded...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px # choropleth maps\n",
    "from IPython.display import Image\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "# plotly maps\n",
    "# import plotly.figure_factory as ff\n",
    "# from urllib.request import urlopen\n",
    "\n",
    "# sys.path.append(os.path.abspath(\"C:/Users/Alex/Documents/My Data Files/COVID Research/analysis/mention_2_hashtag.py\"))\n",
    "\n",
    "# from analysis.functions.mention_2_hashtag import * \n",
    "# from analysis.functions.datamanip import *\n",
    "\n",
    "# n grams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "raw = pd.read_csv('flair.joined.tweets.csv')\n",
    "\n",
    "# changing date to more readable format\n",
    "raw['created_at'] = pd.to_datetime(raw['created_at'])\n",
    "\n",
    "# getting seperated date and time columns\n",
    "raw['date'] = raw['created_at'].dt.date\n",
    "raw['week'] = raw['created_at'].dt.week\n",
    "raw['time'] = raw['created_at'].dt.time\n",
    "raw['hour'] = raw['created_at'].dt.hour\n",
    "\n",
    "min_wk = raw['week'].min()\n",
    "max_wk = raw['week'].max()\n",
    "\n",
    "min_date = raw['date'].min()\n",
    "max_date = raw['date'].max()\n",
    "\n",
    "# changing na to None\n",
    "raw = raw.fillna('None')\n",
    "\n",
    "raw = raw[raw['sentiment'] != 'None']\n",
    "\n",
    "raw['is_negative'] = [1 if 'NEGATIVE' in str(sent) else 0 for sent in raw['sentiment']]\n",
    "raw['is_positive'] = [1 if 'POSITIVE' in str(sent) else 0 for sent in raw['sentiment']]\n",
    "\n",
    "\n",
    "def convert_fips(unknown_fips_list, fin):\n",
    "    \n",
    "    def convert(fipsline):\n",
    "        name, postal, fips= fipsline.strip().split('\\t')\n",
    "\n",
    "        return {fips: name}\n",
    "\n",
    "    fips_dict = {f: n \n",
    "                for dic in [convert(line)for line in open(fin, 'r')]\n",
    "                for f, n in dic.items()}\n",
    "\n",
    "    return [fips_dict[f'{unknown:02d}'] for unknown in unknown_fips_list]\n",
    "\n",
    "raw = raw[raw['statefips'] != 'None']\n",
    "\n",
    "raw['state_name'] = convert_fips([int(float(fips)) for fips in raw['statefips']],\n",
    "                     '../analysis/functions/state.fips.txt')\n",
    "\n",
    "us_state_abbrev = json.load(open('state_abbreviations.json'))\n",
    "\n",
    "raw['state_abv'] = [us_state_abbrev[s] for s in raw['state_name']]\n",
    "\n",
    "raw['fips'] = [f'{int(float(state)):02d}{int(float(county)):03d}' for i, state, county in raw[['statefips', 'countyfips']].itertuples()]\n",
    "raw['count'] = 1\n",
    "# raw.head()\n",
    "\n",
    "all_splits = pd.to_datetime(['2020-03-05', '2020-03-26', '2020-05-01'])\n",
    "raw['stage'] = ['s:1' if date < all_splits[0] else 's:2' if date < all_splits[1] else 's:3' if date < all_splits[2] else 's:4' for date in raw['date']]\n",
    "\n",
    "\n",
    "\n",
    "#########################\n",
    "# thresholds\n",
    "thresholds = [0.8, 0.9, 0.95]\n",
    "for thresh in thresholds:\n",
    "    raw[f't:{thresh}'] = [1 if float(conf) > thresh else 0 for conf in raw['sent_confidence']]\n",
    "\n",
    "col = 't:0.8'\n",
    "raw['category'] = ['NEUT' if t == 0 else 'POS' if p == 1 else 'NEG' for i, n, p, t in raw[['is_negative', 'is_positive', col]].itertuples()]\n",
    "raw['is_neutral'] = [1 if cat == 'NEUT' else 0 for cat in raw['category']]\n",
    "raw['is_positive'] = [1 if cat == 'POS' else 0 for cat in raw['category']]\n",
    "raw['is_negative'] = [1 if cat == 'NEG' else 0 for cat in raw['category']]\n",
    "\n",
    "raw['is_neutral2'] = raw['is_neutral']\n",
    "raw['is_positive2'] = raw['is_positive']\n",
    "raw['is_negative2'] = raw['is_negative']\n",
    "\n",
    "raw['is_neutral3'] = raw['is_neutral']\n",
    "raw['is_positive3'] = raw['is_positive']\n",
    "raw['is_negative3'] = raw['is_negative']\n",
    "\n",
    "##################\n",
    "# cdc\n",
    "\n",
    "keywords = ['social distancing', 'social distance', 'physical distance', '6 feet', 'stay at home', 'school isolation', 'isolation', 'stay home', 'avoid touching', 'mask', 'covering', 'face shield', 'wear a mask', 'surgical mask', 'N95 respirator', 'wearing gloves', 'face shields', 'facial covering', 'skin protection', 'eye protection', 'ppe', 'wash hands', 'hand sanitizer', 'disinfect', 'clean', 'detergent', 'handwashing', 'hand hygiene', 'prevention hygiene', 'sprays', 'concentrates', 'wipes', 'routine cleaning', 'bleach solution', 'test', 'business closure']\n",
    "\n",
    "topics = []\n",
    "indexes = {i:0 for i in range(len(raw.index))}\n",
    "\n",
    "for i, topic in enumerate(keywords):\n",
    "    topics.append([1 if topic in text else 0 for text in raw['ogtext']])\n",
    "\n",
    "for i, kw in enumerate(topics):\n",
    "    for data_ind, value in enumerate(topics[i]):\n",
    "        indexes[data_ind] += value\n",
    "\n",
    "raw['in_cdc'] = [indexes[i] if 0 <= indexes[i] <= 1 else 1 for i in indexes]\n",
    "\n",
    "cdc = raw[raw['in_cdc'] == 1]\n",
    "\n",
    "cdc_splits = pd.to_datetime(['2020-03-12', '2020-04-20', '2020-05-14'])\n",
    "cdc['stage'] = ['s:1' if date < cdc_splits[0] else 's:2' if date < cdc_splits[1] else 's:3' if date < cdc_splits[2] else 's:4' for date in cdc['date']]\n",
    "\n",
    "# print(f'there are a total of {len(cdc.index)} tweets after subsetting for cdc keywords')\n",
    "# print(raw)\n",
    "# print(cdc)\n",
    "print('loaded...')"
   ]
  },
  {
   "source": [
    "# subsetting for cdc keywords"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "there are a total of 53272 tweets after subsetting for cdc keywords\n"
     ]
    }
   ],
   "source": [
    "keywords = ['social distancing', 'social distance', 'physical distance', '6 feet', 'stay at home', 'school isolation', 'isolation', 'stay home', 'avoid touching', 'mask', 'covering', 'face shield', 'wear a mask', 'surgical mask', 'N95 respirator', 'wearing gloves', 'face shields', 'facial covering', 'skin protection', 'eye protection', 'ppe', 'wash hands', 'hand sanitizer', 'disinfect', 'clean', 'detergent', 'handwashing', 'hand hygiene', 'prevention hygiene', 'sprays', 'concentrates', 'wipes', 'routine cleaning', 'bleach solution', 'test', 'business closure']\n",
    "\n",
    "topics = []\n",
    "indexes = {i:0 for i in range(len(raw.index))}\n",
    "\n",
    "for i, topic in enumerate(keywords):\n",
    "    topics.append([1 if topic in text else 0 for text in raw['ogtext']])\n",
    "\n",
    "for i, kw in enumerate(topics):\n",
    "    for data_ind, value in enumerate(topics[i]):\n",
    "        indexes[data_ind] += value\n",
    "\n",
    "raw['in_cdc'] = [indexes[i] if 0 <= indexes[i] <= 1 else 1 for i in indexes]\n",
    "\n",
    "cdc = raw[raw['in_cdc'] == 1]\n",
    "\n",
    "print(f'there are a total of {len(cdc.index)} tweets after subsetting for cdc keywords')"
   ]
  },
  {
   "source": [
    "# income df load"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   FIPStxt Stabr           area_name  Rural_urban_continuum_code_2013  \\\n",
       "0        0    US       United States                              NaN   \n",
       "1     1000    AL             Alabama                              NaN   \n",
       "2     1001    AL  Autauga County, AL                              2.0   \n",
       "3     1003    AL  Baldwin County, AL                              3.0   \n",
       "4     1005    AL  Barbour County, AL                              6.0   \n",
       "\n",
       "   Urban_influence_code_2013  Metro_2013  Civilian_labor_force_2000   \\\n",
       "0                        NaN         NaN                 142,601,667   \n",
       "1                        NaN         NaN                   2,133,223   \n",
       "2                        2.0         1.0                      21,720   \n",
       "3                        2.0         1.0                      69,533   \n",
       "4                        6.0         0.0                      11,373   \n",
       "\n",
       "   Employed_2000   Unemployed_2000   Unemployment_rate_2000  ...  \\\n",
       "0     136,904,680         5,696,987                     4.0  ...   \n",
       "1       2,035,594            97,629                     4.6  ...   \n",
       "2          20,846               874                     4.0  ...   \n",
       "3          66,971             2,562                     3.7  ...   \n",
       "4          10,748               625                     5.5  ...   \n",
       "\n",
       "  Civilian_labor_force_2018 Employed_2018 Unemployed_2018  \\\n",
       "0               161,389,026   155,102,319       6,286,707   \n",
       "1                 2,216,627     2,130,845          85,782   \n",
       "2                    26,196        25,261             935   \n",
       "3                    95,233        91,809           3,424   \n",
       "4                     8,414         7,987             427   \n",
       "\n",
       "   Unemployment_rate_2018  Civilian_labor_force_2019   Employed_2019   \\\n",
       "0                     3.9                 163,100,055     157,115,247   \n",
       "1                     3.9                   2,241,747       2,174,483   \n",
       "2                     3.6                      26,172          25,458   \n",
       "3                     3.6                      97,328          94,675   \n",
       "4                     5.1                       8,537           8,213   \n",
       "\n",
       "   Unemployed_2019   Unemployment_rate_2019 Median_Household_Income_2018  \\\n",
       "0         5,984,808                     3.7                       61,937   \n",
       "1            67,264                     3.0                       49,881   \n",
       "2               714                     2.7                       59,338   \n",
       "3             2,653                     2.7                       57,588   \n",
       "4               324                     3.8                       34,382   \n",
       "\n",
       "  Med_HH_Income_Percent_of_State_Total_2018  \n",
       "0                                       NaN  \n",
       "1                                     100.0  \n",
       "2                                     119.0  \n",
       "3                                     115.5  \n",
       "4                                      68.9  \n",
       "\n",
       "[5 rows x 88 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FIPStxt</th>\n      <th>Stabr</th>\n      <th>area_name</th>\n      <th>Rural_urban_continuum_code_2013</th>\n      <th>Urban_influence_code_2013</th>\n      <th>Metro_2013</th>\n      <th>Civilian_labor_force_2000</th>\n      <th>Employed_2000</th>\n      <th>Unemployed_2000</th>\n      <th>Unemployment_rate_2000</th>\n      <th>...</th>\n      <th>Civilian_labor_force_2018</th>\n      <th>Employed_2018</th>\n      <th>Unemployed_2018</th>\n      <th>Unemployment_rate_2018</th>\n      <th>Civilian_labor_force_2019</th>\n      <th>Employed_2019</th>\n      <th>Unemployed_2019</th>\n      <th>Unemployment_rate_2019</th>\n      <th>Median_Household_Income_2018</th>\n      <th>Med_HH_Income_Percent_of_State_Total_2018</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>US</td>\n      <td>United States</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>142,601,667</td>\n      <td>136,904,680</td>\n      <td>5,696,987</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>161,389,026</td>\n      <td>155,102,319</td>\n      <td>6,286,707</td>\n      <td>3.9</td>\n      <td>163,100,055</td>\n      <td>157,115,247</td>\n      <td>5,984,808</td>\n      <td>3.7</td>\n      <td>61,937</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000</td>\n      <td>AL</td>\n      <td>Alabama</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2,133,223</td>\n      <td>2,035,594</td>\n      <td>97,629</td>\n      <td>4.6</td>\n      <td>...</td>\n      <td>2,216,627</td>\n      <td>2,130,845</td>\n      <td>85,782</td>\n      <td>3.9</td>\n      <td>2,241,747</td>\n      <td>2,174,483</td>\n      <td>67,264</td>\n      <td>3.0</td>\n      <td>49,881</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1001</td>\n      <td>AL</td>\n      <td>Autauga County, AL</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>21,720</td>\n      <td>20,846</td>\n      <td>874</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>26,196</td>\n      <td>25,261</td>\n      <td>935</td>\n      <td>3.6</td>\n      <td>26,172</td>\n      <td>25,458</td>\n      <td>714</td>\n      <td>2.7</td>\n      <td>59,338</td>\n      <td>119.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1003</td>\n      <td>AL</td>\n      <td>Baldwin County, AL</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>69,533</td>\n      <td>66,971</td>\n      <td>2,562</td>\n      <td>3.7</td>\n      <td>...</td>\n      <td>95,233</td>\n      <td>91,809</td>\n      <td>3,424</td>\n      <td>3.6</td>\n      <td>97,328</td>\n      <td>94,675</td>\n      <td>2,653</td>\n      <td>2.7</td>\n      <td>57,588</td>\n      <td>115.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1005</td>\n      <td>AL</td>\n      <td>Barbour County, AL</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>11,373</td>\n      <td>10,748</td>\n      <td>625</td>\n      <td>5.5</td>\n      <td>...</td>\n      <td>8,414</td>\n      <td>7,987</td>\n      <td>427</td>\n      <td>5.1</td>\n      <td>8,537</td>\n      <td>8,213</td>\n      <td>324</td>\n      <td>3.8</td>\n      <td>34,382</td>\n      <td>68.9</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 88 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "income = pd.read_csv('fips_unemp_medhh.csv')\n",
    "income.head()"
   ]
  },
  {
   "source": [
    "# merge dataframes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   id_str                created_at  follower_count  \\\n",
       "0  id:1226325348247310337 2020-02-09 02:02:01+00:00          1196.0   \n",
       "1  id:1233612267415097345 2020-02-29 04:37:38+00:00           823.0   \n",
       "2  id:1228783507033509890 2020-02-15 20:49:52+00:00           324.0   \n",
       "3  id:1227377430362492928 2020-02-11 23:42:37+00:00          3767.0   \n",
       "4  id:1233230888659451904 2020-02-28 03:22:10+00:00           156.0   \n",
       "\n",
       "   friends_count statefips countyfips countyname  is_urban  \\\n",
       "0         1661.0      39.0      117.0     Morrow         0   \n",
       "1         1002.0      39.0      117.0     Morrow         0   \n",
       "2           98.0      39.0      117.0     Morrow         0   \n",
       "3         4007.0      39.0      117.0     Morrow         0   \n",
       "4          162.0      39.0      117.0     Morrow         0   \n",
       "\n",
       "                                              ogtext  \\\n",
       "0  if they pulled the stuff in the sixties and se...   \n",
       "1  so by correct handwashing amp other essential ...   \n",
       "2               this is a disaster waiting to happen   \n",
       "3  thousands of jobs went to because of bad polic...   \n",
       "4  dear powers that be get these test kits develo...   \n",
       "\n",
       "                                           cleantext  ... is_neutral2  \\\n",
       "0  pulled stuff sixty seventy asse handed throw j...  ...           0   \n",
       "1  correct handwash amp essential hygiene routine...  ...           1   \n",
       "2                            disaster waiting happen  ...           0   \n",
       "3  thousand job go bad policy profit follow money...  ...           0   \n",
       "4  dear power test kit develop mass produce send ...  ...           1   \n",
       "\n",
       "  is_positive2 is_negative2 is_neutral3 is_positive3 is_negative3 in_cdc  \\\n",
       "0            0            1           0            0            1      1   \n",
       "1            0            0           1            0            0      1   \n",
       "2            0            1           0            0            1      1   \n",
       "3            0            1           0            0            1      1   \n",
       "4            0            0           1            0            0      1   \n",
       "\n",
       "   unemp_rate median_hh  %_state_total  \n",
       "0         4.1     60452          107.7  \n",
       "1         4.1     60452          107.7  \n",
       "2         4.1     60452          107.7  \n",
       "3         4.1     60452          107.7  \n",
       "4         4.1     60452          107.7  \n",
       "\n",
       "[5 rows x 42 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_str</th>\n      <th>created_at</th>\n      <th>follower_count</th>\n      <th>friends_count</th>\n      <th>statefips</th>\n      <th>countyfips</th>\n      <th>countyname</th>\n      <th>is_urban</th>\n      <th>ogtext</th>\n      <th>cleantext</th>\n      <th>...</th>\n      <th>is_neutral2</th>\n      <th>is_positive2</th>\n      <th>is_negative2</th>\n      <th>is_neutral3</th>\n      <th>is_positive3</th>\n      <th>is_negative3</th>\n      <th>in_cdc</th>\n      <th>unemp_rate</th>\n      <th>median_hh</th>\n      <th>%_state_total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id:1226325348247310337</td>\n      <td>2020-02-09 02:02:01+00:00</td>\n      <td>1196.0</td>\n      <td>1661.0</td>\n      <td>39.0</td>\n      <td>117.0</td>\n      <td>Morrow</td>\n      <td>0</td>\n      <td>if they pulled the stuff in the sixties and se...</td>\n      <td>pulled stuff sixty seventy asse handed throw j...</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4.1</td>\n      <td>60452</td>\n      <td>107.7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id:1233612267415097345</td>\n      <td>2020-02-29 04:37:38+00:00</td>\n      <td>823.0</td>\n      <td>1002.0</td>\n      <td>39.0</td>\n      <td>117.0</td>\n      <td>Morrow</td>\n      <td>0</td>\n      <td>so by correct handwashing amp other essential ...</td>\n      <td>correct handwash amp essential hygiene routine...</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4.1</td>\n      <td>60452</td>\n      <td>107.7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id:1228783507033509890</td>\n      <td>2020-02-15 20:49:52+00:00</td>\n      <td>324.0</td>\n      <td>98.0</td>\n      <td>39.0</td>\n      <td>117.0</td>\n      <td>Morrow</td>\n      <td>0</td>\n      <td>this is a disaster waiting to happen</td>\n      <td>disaster waiting happen</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4.1</td>\n      <td>60452</td>\n      <td>107.7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id:1227377430362492928</td>\n      <td>2020-02-11 23:42:37+00:00</td>\n      <td>3767.0</td>\n      <td>4007.0</td>\n      <td>39.0</td>\n      <td>117.0</td>\n      <td>Morrow</td>\n      <td>0</td>\n      <td>thousands of jobs went to because of bad polic...</td>\n      <td>thousand job go bad policy profit follow money...</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4.1</td>\n      <td>60452</td>\n      <td>107.7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id:1233230888659451904</td>\n      <td>2020-02-28 03:22:10+00:00</td>\n      <td>156.0</td>\n      <td>162.0</td>\n      <td>39.0</td>\n      <td>117.0</td>\n      <td>Morrow</td>\n      <td>0</td>\n      <td>dear powers that be get these test kits develo...</td>\n      <td>dear power test kit develop mass produce send ...</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4.1</td>\n      <td>60452</td>\n      <td>107.7</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 42 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "stats_df = income[income['FIPStxt'].isin(raw['fips'].unique())][['FIPStxt', 'Unemployment_rate_2019', 'Median_Household_Income_2018', 'Med_HH_Income_Percent_of_State_Total_2018']]\n",
    "\n",
    "stats_df.columns = ['fips', 'unemp_rate', 'median_hh', '%_state_total']\n",
    "\n",
    "stats_df['median_hh'] = stats_df['median_hh'].replace(',','', regex = True)\n",
    "stats_df['fips'] = stats_df['fips'].astype('str')\n",
    "raw = pd.merge(cdc, stats_df, on='fips')\n",
    "\n",
    "# had to pull peurto rico stats\n",
    "raw = raw[~raw['median_hh'].isna()]\n",
    "raw['median_hh'] = raw['median_hh'].astype('int')\n",
    "\n",
    "\n",
    "raw.head()"
   ]
  },
  {
   "source": [
    "# stats on unemployment rate and median household income"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "median household income stats\ncount     40870.000000\nmean      65723.964497\nstd       17698.484566\nmin       29380.000000\n25%       52910.000000\n50%       60862.000000\n75%       76255.000000\nmax      140382.000000\nName: median_hh, dtype: float64\n\nunemployment rate stats\ncount    40870.000000\nmean         3.621304\nstd          0.883700\nmin          1.800000\n25%          3.000000\n50%          3.500000\n75%          4.000000\nmax         12.200000\nName: unemp_rate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('median household income stats')\n",
    "print(raw['median_hh'].describe())\n",
    "print()\n",
    "print('unemployment rate stats')\n",
    "print(raw['unemp_rate'].describe())"
   ]
  },
  {
   "source": [
    "# median household"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = raw.groupby(['fips']).agg({'is_negative':'mean', 'is_positive':'mean', 'is_neutral':'mean', 'median_hh':'mean', 'unemp_rate':'mean', 'state_name':'max', 'count':'count'}).reset_index()\n",
    "\n",
    "counties = counties[counties['count'] > 15]\n",
    "\n",
    "# sns.regplot(x='median_hh', y='is_negative', data=counties, marker='+')"
   ]
  },
  {
   "source": [
    "# unemployment rate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.regplot(x='unemp_rate', y='is_negative', data=counties, marker='+')"
   ]
  },
  {
   "source": [
    "# pearsons r"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  counties[['is_negative','unemp_rate','median_hh']].corr()"
   ]
  },
  {
   "source": [
    "# pearsons r squared"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  counties[['is_negative','unemp_rate','median_hh']].corr()**2"
   ]
  },
  {
   "source": [
    "# very low correlations compared to non-cdc subsetted data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "negative:   r                  p\n(0.07396401802178429, 0.1692216453367042)\n\npositive:   r                  p\n(-0.1005989857272788, 0.06121476762571336)\n\nneutral:   r                  p\n(0.030663165019377214, 0.5691767706547305)\n\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "cats = 'negative positive neutral'.split(' ')\n",
    "\n",
    "for cat in cats:\n",
    "    x= counties[f'is_{cat}']\n",
    "    y= counties['unemp_rate']\n",
    "\n",
    "    print(f'{cat}:   r                  p')\n",
    "    print(scipy.stats.pearsonr(x, y))    # Pearson's r\n",
    "    print()\n",
    "\n",
    "# print(scipy.stats.spearmanr(x, y))   # Spearman's rho\n",
    "\n",
    "# print(scipy.stats.kendalltau(x, y))  # Kendall's tau\n"
   ]
  }
 ]
}