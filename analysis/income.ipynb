{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bit31a300f32e4a4979894c2ccf59316df7",
   "display_name": "Python 3.8.3 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# looking into unemployment rate and median household income"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loaded...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px # choropleth maps\n",
    "from IPython.display import Image\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "# plotly maps\n",
    "# import plotly.figure_factory as ff\n",
    "# from urllib.request import urlopen\n",
    "\n",
    "# sys.path.append(os.path.abspath(\"C:/Users/Alex/Documents/My Data Files/COVID Research/analysis/mention_2_hashtag.py\"))\n",
    "\n",
    "# from analysis.functions.mention_2_hashtag import * \n",
    "# from analysis.functions.datamanip import *\n",
    "\n",
    "# n grams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "raw = pd.read_csv('flair.joined.tweets.csv')\n",
    "\n",
    "# changing date to more readable format\n",
    "raw['created_at'] = pd.to_datetime(raw['created_at'])\n",
    "\n",
    "# getting seperated date and time columns\n",
    "raw['date'] = raw['created_at'].dt.date\n",
    "raw['week'] = raw['created_at'].dt.week\n",
    "raw['time'] = raw['created_at'].dt.time\n",
    "raw['hour'] = raw['created_at'].dt.hour\n",
    "\n",
    "min_wk = raw['week'].min()\n",
    "max_wk = raw['week'].max()\n",
    "\n",
    "min_date = raw['date'].min()\n",
    "max_date = raw['date'].max()\n",
    "\n",
    "# changing na to None\n",
    "raw = raw.fillna('None')\n",
    "\n",
    "raw = raw[raw['sentiment'] != 'None']\n",
    "\n",
    "raw['is_negative'] = [1 if 'NEGATIVE' in str(sent) else 0 for sent in raw['sentiment']]\n",
    "raw['is_positive'] = [1 if 'POSITIVE' in str(sent) else 0 for sent in raw['sentiment']]\n",
    "\n",
    "\n",
    "def convert_fips(unknown_fips_list, fin):\n",
    "    \n",
    "    def convert(fipsline):\n",
    "        name, postal, fips= fipsline.strip().split('\\t')\n",
    "\n",
    "        return {fips: name}\n",
    "\n",
    "    fips_dict = {f: n \n",
    "                for dic in [convert(line)for line in open(fin, 'r')]\n",
    "                for f, n in dic.items()}\n",
    "\n",
    "    return [fips_dict[f'{unknown:02d}'] for unknown in unknown_fips_list]\n",
    "\n",
    "raw = raw[raw['statefips'] != 'None']\n",
    "\n",
    "raw['state_name'] = convert_fips([int(float(fips)) for fips in raw['statefips']],\n",
    "                     '../analysis/functions/state.fips.txt')\n",
    "\n",
    "us_state_abbrev = json.load(open('state_abbreviations.json'))\n",
    "\n",
    "raw['state_abv'] = [us_state_abbrev[s] for s in raw['state_name']]\n",
    "\n",
    "raw['fips'] = [f'{int(float(state)):02d}{int(float(county)):03d}' for i, state, county in raw[['statefips', 'countyfips']].itertuples()]\n",
    "raw['count'] = 1\n",
    "# raw.head()\n",
    "\n",
    "all_splits = pd.to_datetime(['2020-03-05', '2020-03-26', '2020-05-01'])\n",
    "raw['stage'] = ['s:1' if date < all_splits[0] else 's:2' if date < all_splits[1] else 's:3' if date < all_splits[2] else 's:4' for date in raw['date']]\n",
    "\n",
    "\n",
    "\n",
    "#########################\n",
    "# thresholds\n",
    "thresholds = [0.8, 0.9, 0.95]\n",
    "for thresh in thresholds:\n",
    "    raw[f't:{thresh}'] = [1 if float(conf) > thresh else 0 for conf in raw['sent_confidence']]\n",
    "\n",
    "col = 't:0.8'\n",
    "raw['category'] = ['NEUT' if t == 0 else 'POS' if p == 1 else 'NEG' for i, n, p, t in raw[['is_negative', 'is_positive', col]].itertuples()]\n",
    "raw['is_neutral'] = [1 if cat == 'NEUT' else 0 for cat in raw['category']]\n",
    "raw['is_positive'] = [1 if cat == 'POS' else 0 for cat in raw['category']]\n",
    "raw['is_negative'] = [1 if cat == 'NEG' else 0 for cat in raw['category']]\n",
    "\n",
    "raw['is_neutral2'] = raw['is_neutral']\n",
    "raw['is_positive2'] = raw['is_positive']\n",
    "raw['is_negative2'] = raw['is_negative']\n",
    "\n",
    "raw['is_neutral3'] = raw['is_neutral']\n",
    "raw['is_positive3'] = raw['is_positive']\n",
    "raw['is_negative3'] = raw['is_negative']\n",
    "\n",
    "##################\n",
    "# cdc\n",
    "\n",
    "keywords = ['social distancing', 'social distance', 'physical distance', '6 feet', 'stay at home', 'school isolation', 'isolation', 'stay home', 'avoid touching', 'mask', 'covering', 'face shield', 'wear a mask', 'surgical mask', 'N95 respirator', 'wearing gloves', 'face shields', 'facial covering', 'skin protection', 'eye protection', 'ppe', 'wash hands', 'hand sanitizer', 'disinfect', 'clean', 'detergent', 'handwashing', 'hand hygiene', 'prevention hygiene', 'sprays', 'concentrates', 'wipes', 'routine cleaning', 'bleach solution', 'test', 'business closure']\n",
    "\n",
    "topics = []\n",
    "indexes = {i:0 for i in range(len(raw.index))}\n",
    "\n",
    "for i, topic in enumerate(keywords):\n",
    "    topics.append([1 if topic in text else 0 for text in raw['ogtext']])\n",
    "\n",
    "for i, kw in enumerate(topics):\n",
    "    for data_ind, value in enumerate(topics[i]):\n",
    "        indexes[data_ind] += value\n",
    "\n",
    "raw['in_cdc'] = [indexes[i] if 0 <= indexes[i] <= 1 else 1 for i in indexes]\n",
    "\n",
    "cdc = raw[raw['in_cdc'] == 1]\n",
    "\n",
    "cdc_splits = pd.to_datetime(['2020-03-12', '2020-04-20', '2020-05-14'])\n",
    "cdc['stage'] = ['s:1' if date < cdc_splits[0] else 's:2' if date < cdc_splits[1] else 's:3' if date < cdc_splits[2] else 's:4' for date in cdc['date']]\n",
    "\n",
    "# print(f'there are a total of {len(cdc.index)} tweets after subsetting for cdc keywords')\n",
    "# print(raw)\n",
    "# print(cdc)\n",
    "print('loaded...')"
   ]
  },
  {
   "source": [
    "# getting data for 2019 unemployment and 2018 median income\n",
    "\n",
    "https://www.ers.usda.gov/data-products/county-level-data-sets/download-data/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   FIPStxt Stabr           area_name  Rural_urban_continuum_code_2013  \\\n",
       "0        0    US       United States                              NaN   \n",
       "1     1000    AL             Alabama                              NaN   \n",
       "2     1001    AL  Autauga County, AL                              2.0   \n",
       "3     1003    AL  Baldwin County, AL                              3.0   \n",
       "4     1005    AL  Barbour County, AL                              6.0   \n",
       "\n",
       "   Urban_influence_code_2013  Metro_2013  Civilian_labor_force_2000   \\\n",
       "0                        NaN         NaN                 142,601,667   \n",
       "1                        NaN         NaN                   2,133,223   \n",
       "2                        2.0         1.0                      21,720   \n",
       "3                        2.0         1.0                      69,533   \n",
       "4                        6.0         0.0                      11,373   \n",
       "\n",
       "   Employed_2000   Unemployed_2000   Unemployment_rate_2000  ...  \\\n",
       "0     136,904,680         5,696,987                     4.0  ...   \n",
       "1       2,035,594            97,629                     4.6  ...   \n",
       "2          20,846               874                     4.0  ...   \n",
       "3          66,971             2,562                     3.7  ...   \n",
       "4          10,748               625                     5.5  ...   \n",
       "\n",
       "  Civilian_labor_force_2018 Employed_2018 Unemployed_2018  \\\n",
       "0               161,389,026   155,102,319       6,286,707   \n",
       "1                 2,216,627     2,130,845          85,782   \n",
       "2                    26,196        25,261             935   \n",
       "3                    95,233        91,809           3,424   \n",
       "4                     8,414         7,987             427   \n",
       "\n",
       "   Unemployment_rate_2018  Civilian_labor_force_2019   Employed_2019   \\\n",
       "0                     3.9                 163,100,055     157,115,247   \n",
       "1                     3.9                   2,241,747       2,174,483   \n",
       "2                     3.6                      26,172          25,458   \n",
       "3                     3.6                      97,328          94,675   \n",
       "4                     5.1                       8,537           8,213   \n",
       "\n",
       "   Unemployed_2019   Unemployment_rate_2019 Median_Household_Income_2018  \\\n",
       "0         5,984,808                     3.7                       61,937   \n",
       "1            67,264                     3.0                       49,881   \n",
       "2               714                     2.7                       59,338   \n",
       "3             2,653                     2.7                       57,588   \n",
       "4               324                     3.8                       34,382   \n",
       "\n",
       "  Med_HH_Income_Percent_of_State_Total_2018  \n",
       "0                                       NaN  \n",
       "1                                     100.0  \n",
       "2                                     119.0  \n",
       "3                                     115.5  \n",
       "4                                      68.9  \n",
       "\n",
       "[5 rows x 88 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FIPStxt</th>\n      <th>Stabr</th>\n      <th>area_name</th>\n      <th>Rural_urban_continuum_code_2013</th>\n      <th>Urban_influence_code_2013</th>\n      <th>Metro_2013</th>\n      <th>Civilian_labor_force_2000</th>\n      <th>Employed_2000</th>\n      <th>Unemployed_2000</th>\n      <th>Unemployment_rate_2000</th>\n      <th>...</th>\n      <th>Civilian_labor_force_2018</th>\n      <th>Employed_2018</th>\n      <th>Unemployed_2018</th>\n      <th>Unemployment_rate_2018</th>\n      <th>Civilian_labor_force_2019</th>\n      <th>Employed_2019</th>\n      <th>Unemployed_2019</th>\n      <th>Unemployment_rate_2019</th>\n      <th>Median_Household_Income_2018</th>\n      <th>Med_HH_Income_Percent_of_State_Total_2018</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>US</td>\n      <td>United States</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>142,601,667</td>\n      <td>136,904,680</td>\n      <td>5,696,987</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>161,389,026</td>\n      <td>155,102,319</td>\n      <td>6,286,707</td>\n      <td>3.9</td>\n      <td>163,100,055</td>\n      <td>157,115,247</td>\n      <td>5,984,808</td>\n      <td>3.7</td>\n      <td>61,937</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000</td>\n      <td>AL</td>\n      <td>Alabama</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2,133,223</td>\n      <td>2,035,594</td>\n      <td>97,629</td>\n      <td>4.6</td>\n      <td>...</td>\n      <td>2,216,627</td>\n      <td>2,130,845</td>\n      <td>85,782</td>\n      <td>3.9</td>\n      <td>2,241,747</td>\n      <td>2,174,483</td>\n      <td>67,264</td>\n      <td>3.0</td>\n      <td>49,881</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1001</td>\n      <td>AL</td>\n      <td>Autauga County, AL</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>21,720</td>\n      <td>20,846</td>\n      <td>874</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>26,196</td>\n      <td>25,261</td>\n      <td>935</td>\n      <td>3.6</td>\n      <td>26,172</td>\n      <td>25,458</td>\n      <td>714</td>\n      <td>2.7</td>\n      <td>59,338</td>\n      <td>119.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1003</td>\n      <td>AL</td>\n      <td>Baldwin County, AL</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>69,533</td>\n      <td>66,971</td>\n      <td>2,562</td>\n      <td>3.7</td>\n      <td>...</td>\n      <td>95,233</td>\n      <td>91,809</td>\n      <td>3,424</td>\n      <td>3.6</td>\n      <td>97,328</td>\n      <td>94,675</td>\n      <td>2,653</td>\n      <td>2.7</td>\n      <td>57,588</td>\n      <td>115.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1005</td>\n      <td>AL</td>\n      <td>Barbour County, AL</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>11,373</td>\n      <td>10,748</td>\n      <td>625</td>\n      <td>5.5</td>\n      <td>...</td>\n      <td>8,414</td>\n      <td>7,987</td>\n      <td>427</td>\n      <td>5.1</td>\n      <td>8,537</td>\n      <td>8,213</td>\n      <td>324</td>\n      <td>3.8</td>\n      <td>34,382</td>\n      <td>68.9</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 88 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "income = pd.read_csv('fips_unemp_medhh.csv')\n",
    "income.head()"
   ]
  },
  {
   "source": [
    "# joining datasets\n",
    "\n",
    "no info for puerto rico, so those tweets had to be pulled from the raw data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   id_str                created_at  follower_count  \\\n",
       "0  id:1226763665036075008 2020-02-10 07:03:44+00:00           270.0   \n",
       "1  id:1226773799342706689 2020-02-10 07:44:00+00:00           312.0   \n",
       "2  id:1226327068389998592 2020-02-09 02:08:51+00:00          2887.0   \n",
       "3  id:1233697011758587907 2020-02-29 10:14:23+00:00             7.0   \n",
       "4  id:1233697205405437953 2020-02-29 10:15:09+00:00             7.0   \n",
       "\n",
       "   friends_count statefips countyfips countyname  is_urban  \\\n",
       "0          539.0      32.0        3.0      Clark         1   \n",
       "1          125.0      32.0        3.0      Clark         1   \n",
       "2          831.0      32.0        3.0      Clark         1   \n",
       "3          169.0      32.0        3.0      Clark         1   \n",
       "4          169.0      32.0        3.0      Clark         1   \n",
       "\n",
       "                                              ogtext  \\\n",
       "0  having a mocha and avoiding coronavirus at the...   \n",
       "1  sadly nothing will be done to help the people ...   \n",
       "2  the world is grieving for the wuhan doctor who...   \n",
       "3  risk of global coronavirus spread very high wa...   \n",
       "4         coronavirus what are the chances of dying    \n",
       "\n",
       "                                           cleantext  ... is_neutral2  \\\n",
       "0               have mocha avoid coronavirus airport  ...           0   \n",
       "1  sadly help people china communist government u...  ...           0   \n",
       "2  world grieving wuhan doctor try warn colleague...  ...           0   \n",
       "3  risk global coronavirus spread high warn china...  ...           0   \n",
       "4                            coronavirus chances die  ...           0   \n",
       "\n",
       "  is_positive2 is_negative2 is_neutral3 is_positive3 is_negative3 in_cdc  \\\n",
       "0            1            0           0            1            0      0   \n",
       "1            0            1           0            0            1      0   \n",
       "2            0            1           0            0            1      0   \n",
       "3            0            1           0            0            1      0   \n",
       "4            0            1           0            0            1      0   \n",
       "\n",
       "   unemp_rate median_hh  %_state_total  \n",
       "0         4.0     57155           97.3  \n",
       "1         4.0     57155           97.3  \n",
       "2         4.0     57155           97.3  \n",
       "3         4.0     57155           97.3  \n",
       "4         4.0     57155           97.3  \n",
       "\n",
       "[5 rows x 42 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_str</th>\n      <th>created_at</th>\n      <th>follower_count</th>\n      <th>friends_count</th>\n      <th>statefips</th>\n      <th>countyfips</th>\n      <th>countyname</th>\n      <th>is_urban</th>\n      <th>ogtext</th>\n      <th>cleantext</th>\n      <th>...</th>\n      <th>is_neutral2</th>\n      <th>is_positive2</th>\n      <th>is_negative2</th>\n      <th>is_neutral3</th>\n      <th>is_positive3</th>\n      <th>is_negative3</th>\n      <th>in_cdc</th>\n      <th>unemp_rate</th>\n      <th>median_hh</th>\n      <th>%_state_total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id:1226763665036075008</td>\n      <td>2020-02-10 07:03:44+00:00</td>\n      <td>270.0</td>\n      <td>539.0</td>\n      <td>32.0</td>\n      <td>3.0</td>\n      <td>Clark</td>\n      <td>1</td>\n      <td>having a mocha and avoiding coronavirus at the...</td>\n      <td>have mocha avoid coronavirus airport</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>57155</td>\n      <td>97.3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id:1226773799342706689</td>\n      <td>2020-02-10 07:44:00+00:00</td>\n      <td>312.0</td>\n      <td>125.0</td>\n      <td>32.0</td>\n      <td>3.0</td>\n      <td>Clark</td>\n      <td>1</td>\n      <td>sadly nothing will be done to help the people ...</td>\n      <td>sadly help people china communist government u...</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>57155</td>\n      <td>97.3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id:1226327068389998592</td>\n      <td>2020-02-09 02:08:51+00:00</td>\n      <td>2887.0</td>\n      <td>831.0</td>\n      <td>32.0</td>\n      <td>3.0</td>\n      <td>Clark</td>\n      <td>1</td>\n      <td>the world is grieving for the wuhan doctor who...</td>\n      <td>world grieving wuhan doctor try warn colleague...</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>57155</td>\n      <td>97.3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id:1233697011758587907</td>\n      <td>2020-02-29 10:14:23+00:00</td>\n      <td>7.0</td>\n      <td>169.0</td>\n      <td>32.0</td>\n      <td>3.0</td>\n      <td>Clark</td>\n      <td>1</td>\n      <td>risk of global coronavirus spread very high wa...</td>\n      <td>risk global coronavirus spread high warn china...</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>57155</td>\n      <td>97.3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id:1233697205405437953</td>\n      <td>2020-02-29 10:15:09+00:00</td>\n      <td>7.0</td>\n      <td>169.0</td>\n      <td>32.0</td>\n      <td>3.0</td>\n      <td>Clark</td>\n      <td>1</td>\n      <td>coronavirus what are the chances of dying</td>\n      <td>coronavirus chances die</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>57155</td>\n      <td>97.3</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 42 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "stats_df = income[income['FIPStxt'].isin(raw['fips'].unique())][['FIPStxt', 'Unemployment_rate_2019', 'Median_Household_Income_2018', 'Med_HH_Income_Percent_of_State_Total_2018']]\n",
    "\n",
    "stats_df.columns = ['fips', 'unemp_rate', 'median_hh', '%_state_total']\n",
    "\n",
    "stats_df['median_hh'] = stats_df['median_hh'].replace(',','', regex = True)\n",
    "stats_df['fips'] = stats_df['fips'].astype('str')\n",
    "raw = pd.merge(raw, stats_df, on='fips')\n",
    "\n",
    "# had to pull peurto rico stats\n",
    "raw = raw[~raw['median_hh'].isna()]\n",
    "raw['median_hh'] = raw['median_hh'].astype('int')\n",
    "\n",
    "\n",
    "raw.head()"
   ]
  },
  {
   "source": [
    "# stats of new info"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "median household income stats\ncount    263748.000000\nmean      65584.382960\nstd       17706.438501\nmin       28024.000000\n25%       52651.000000\n50%       60862.000000\n75%       76255.000000\nmax      140382.000000\nName: median_hh, dtype: float64\n\nunemployment rate stats\ncount    263748.000000\nmean          3.616948\nstd           0.868748\nmin           1.700000\n25%           3.000000\n50%           3.500000\n75%           4.000000\nmax          15.500000\nName: unemp_rate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('median household income stats')\n",
    "print(raw['median_hh'].describe())\n",
    "print()\n",
    "print('unemployment rate stats')\n",
    "print(raw['unemp_rate'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = raw.groupby(['fips']).agg({'is_negative':'mean', 'is_positive':'mean', 'is_neutral':'mean', 'median_hh':'mean', 'unemp_rate':'mean', 'state_name':'max', 'count':'count'}).reset_index()\n",
    "\n",
    "counties = counties[counties['count'] > 15]\n",
    "\n",
    "# sns.regplot(x='median_hh', y='is_negative', data=counties, marker='+')"
   ]
  },
  {
   "source": [
    "# sns.regplot(x='unemp_rate', y='is_negative', data=counties, marker='+')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 9,
   "outputs": []
  },
  {
   "source": [
    "# pearsons r"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  counties[['is_negative','unemp_rate','median_hh']].corr()"
   ]
  },
  {
   "source": [
    "# pearsons r squared"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  counties[['is_negative','unemp_rate','median_hh']].corr()**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = .1464128*((len(counties.index)-2)**(0.5))/((1-.1464128**2)**(0.5))\n",
    "# print(t)"
   ]
  },
  {
   "source": [
    "# different significance tests"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "negative:   r                  p\n(0.11400209658607442, 0.0012827161184116379)\n\npositive:   r                  p\n(-0.17412227296496105, 7.829792312189126e-07)\n\nneutral:   r                  p\n(0.08835706218179995, 0.012693700035200746)\n\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "cats = 'negative positive neutral'.split(' ')\n",
    "\n",
    "for cat in cats:\n",
    "    x= counties[f'is_{cat}']\n",
    "    y= counties['unemp_rate']\n",
    "\n",
    "    print(f'{cat}:   r                  p')\n",
    "    print(scipy.stats.pearsonr(x, y))    # Pearson's r\n",
    "    print()\n",
    "\n",
    "# print(scipy.stats.spearmanr(x, y))   # Spearman's rho\n",
    "\n",
    "# print(scipy.stats.kendalltau(x, y))  # Kendall's tau\n"
   ]
  },
  {
   "source": [
    "# correlation of counties' avg negative and unemployment rate that mention topic\n",
    "\n",
    "subset of tweets that contain topic, average of negative rate is taken for those tweets only"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "# topics = ['test', \"social distancing\", 'ppe', \"mask\", \"stay home\"]\n",
    "\n",
    "# for i, topic in enumerate(topics):\n",
    "#     raw[topic] = [1 if topic in text else 0 for text in raw['ogtext']]\n",
    "\n",
    "# for topic in topics:\n",
    "#     print(f'for topic: {topic}')\n",
    "\n",
    "#     counties = raw[raw[topic]==1].groupby(['fips']).agg({'is_negative':'mean', 'median_hh':'mean', 'unemp_rate':'mean', 'state_name':'max', 'count':'count'}).reset_index()\n",
    "\n",
    "#     counties = counties[counties['count'] > 15]\n",
    "\n",
    "#     sns.regplot(x='unemp_rate', y='is_negative', data=counties, marker='+')\n",
    "#     plt.show()\n",
    "#     print(counties[['is_negative','unemp_rate']].corr()**2)\n",
    "#     x= counties['is_negative']\n",
    "#     y= counties['unemp_rate']\n",
    "#     print(scipy.stats.pearsonr(x, y))\n",
    "#     print('-----------------')"
   ]
  }
 ]
}